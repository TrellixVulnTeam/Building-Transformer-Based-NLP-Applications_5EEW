{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"000_Introduction.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"BGKJ2je_Dlvm"},"source":["<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"헤더\" style=\"width: 400px;\"/> </a>"]},{"cell_type":"markdown","metadata":{"id":"nQ4wLRSPDlvo"},"source":["# Transformer 기반 자연어 처리 애플리케이션 구축\n","### 3부: Production Deployment\n","\n","이 랩의 목표는 예제 NLP 모델을 프로덕션 추론 서버에 배포하는 것입니다. \n","\n","<img style=\"float: right;\" src=\"images/triton-diagram.jpg\" width=500>\n","\n","우리 프로젝트에서는 NVIDIA Triton Inference Server를 사용합니다.  프로덕션 추론에서 얻는 \"결과\"는 모델의 프레임워크를 직접 사용해서 얻는 결과와 동일하지만 Triton을 사용할 경우 추가적인 이점이 있습니다.\n","* 동시 모델 실행(여러 모델을 동시에 실행할 수 있음)\n","* 동적 배치(더 뛰어난 처리량)\n","* 모델 live 교체(서버 실행 중에 업데이트할 수 있음)\n","* Docker 컨테이너 사용 가능(포터블)\n","* 여러 프레임워크 지원(TensorRT, TensorFlow, PyTorch, ONNX)\n","\n","## 목차\n","1. [모델 내보내기](010_ExportingTheModel.ipynb)<br/>\n","    다음과 같은 내용을 배웁니다.\n","    - PyTorch에서 트레이닝된 모델을 서버 효율적인 형식으로 변환<br/>\n","    - 감소된 정밀도 및 TensorRT 모델 최적화 적용 <br/>\n","2. [모델 호스팅](020_HostingTheModel.ipynb)<br/>\n","    다음과 같은 내용을 배웁니다.\n","    - NVIDIA Triton Inference Server를 사용하여 프로덕션에 모델 배포<br/>\n","    - 모델 구성을 통해 NVIDIA Triton의 일부 기본 기능 제어 <br/>\n","    - 내보내기 형식 및 구성 옵션이 성능 및 비용에 미치는 영향 평가<br/>\n","3. [서버 성능](030_ServerPerformance.ipynb)<br/>\n","    다음과 같은 내용을 배웁니다.\n","    - 다양한 Triton 구성 옵션이 서빙 성능에 미치는 영향 평가<br/>\n","    - 프로덕션의 추론 성능 모니터링 <br/>\n","4. [모델 사용](040_UsingTheModel.ipynb)<br/>\n","    다음과 같은 내용을 배웁니다.\n","    - Triton에서 노출되는 API를 활용할 수 있는 단순한 애플리케이션 구축<br/>\n","    - 더 복잡한 애플리케이션 및 모델 파이프라인 배포를 위한 옵션 논의<br/>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"7dEvrr-XDlvq"},"source":["### JupyterLab\n","이 핸즈온 랩에서는 [JupyterLab](https://jupyterlab.readthedocs.io/en/stable/)을 사용하여 환경을 관리합니다.  [JupyterLab 인터페이스](https://jupyterlab.readthedocs.io/en/stable/user/interface.html)는 인터랙티브 iPython 노트북에 액세스할 수 있을 뿐 아니라 Ubuntu 운영 체제로 환경 및 터미널 창의 폴더 구조에 액세스할 수 있는 대시보드입니다. 표시되는 첫 번째 보기에는 상단의 **메뉴 모음**, **왼쪽 사이드바**의 **파일 탐색기**, 처음에 \"시작 관리자\" 페이지로 열리는 **메인 작업 영역**이 포함되어 있습니다. \n","\n","<img src=\"images/jl_launcher.png\">\n","\n","파일 탐색기는 다른 파일 탐색기와 같은 방법으로 탐색할 수 있습니다. 항목을 더블 클릭하면 내용이 포함된 새 탭이 열립니다.\n","\n","메인 작업 영역에는 필요에 따라 닫거나 이동하거나 편집할 수 있는 탭으로 구분된 열린 파일 보기가 포함되어 있습니다. \n","\n","이 노트북을 포함한 노트북은 일련의 콘텐츠와 코드 **셀**로 구성됩니다.  코드 셀에서 코드를 실행하려면 셀을 강조 표시한 상태에서 `Shift+Enter`를 누르거나 위의 메뉴 모음에서 \"실행\" 버튼을 누르십시오. 때로는 콘텐츠 셀이 편집 모드로 전환됩니다. `Shift+Enter`를 누르면 읽을 수 있는 형식으로 다시 전환됩니다.\n","\n","아래 셀에서 간단한 출력 문을 실행해 보십시오."]},{"cell_type":"code","metadata":{"id":"JaiKu9oQDlvr"},"source":["# Highlight this cell and click [Shift+Enter] to execute\n","print('This is just a simple print statement')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fYUqYml8Dlvr"},"source":["<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"헤더\" style=\"width: 400px;\"/> </a>"]}]}