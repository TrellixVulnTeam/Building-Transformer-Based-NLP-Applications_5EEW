{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"../images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 Positional Encoding \n",
    "\n",
    "언어 모델은 문장에 있는 단어의 순차적인 특성을 활용해야 합니다. Transformer 모델은 순환 또는 합성곱 유닛을 포함하지 않으므로 입력 시퀀스의 단어 순서를 설명하는 데 포지셔널 인코딩(PE)이 사용됩니다. 포지셔널 인코딩은 임베딩과 차원이 동일하므로(d<sub>model</sub>) 두 개를 합칠 수 있습니다(그림 4 참조). 따라서 모델이 입력 텍스트에서 각 단어의 위치를 이해할 수 있습니다.\n",
    "\n",
    "이 문서에서 작성자는 포지셔널 인코딩에 주파수가 서로 다른 사인 및 코사인 함수를 사용합니다.\n",
    "\n",
    "\n",
    "<img src=\"../images/pe.png\" width=\"400\">\n",
    "여기에서 <i>pos</i>는 위치이고, <i>i</i>는 차원입니다. 예제를 통해 위의 공식을 설명해 보겠습니다.\n",
    "\n",
    "d<sub>model</sub> = 4라고 가정해 봅시다. 즉, W 입력 시퀀스 위치로 <i>Pos</i> ∈ [0, L-1]은 4차원 배관으로 표현됩니다. 전자<sub>W</sub> 벡터. <i>i</i> ∈ [0, 255]를 설정하면 4차원 임베딩 벡터의 짝수 지수에 대해 sin(pos/10000<i><sup>2i/d<sub>model</sub></sup></i>) 함수를 사용하고, 홀수 지수에 대해서는 cos(pos/10000<i><sup>2i/d<sub>model</sub></sup></i>)를 사용합니다. \n",
    "\n",
    "입력 문장의 첫 번째 위치는 pos = 0이고, 임베딩 벡터의 첫 번째 지수는 <i>k</i>=0입니다. 이제, 임베딩 벡터의 첫 번째 차원 k = 0의 첫 번째 PE(포지셔널 인코딩)는 sin(0/10000<sup>0/4</sup>)이 되고, 두 번째 차원 k = 1의 두 번째 PE는 cos(0/10000<sup>0/4</sup>)가 됩니다. 세 번째 차원 k = 2와 네 번째 차원 k =3의 경우 PE는 각각 sin(0/10000<sup>2/4</sup>) 및 cos(0/10000<sup>2/4</sup>)가 됩니다. \n",
    "\n",
    "이제 입력 시퀀스의 첫 번째 단어에 대한 포지셔널 인코딩을 작성할 수 있습니다.\n",
    "\n",
    "PE (pos =0) = [sin(0/10000<sup>0/4</sup>), cos(0/10000<sup>0/4</sup>), sin(0/10000<sup>2/4</sup>), cos(0/10000<sup>2/4</sup>)].\n",
    "\n",
    "간단한 형식으로 나타내면 다음과 같습니다.\n",
    "\n",
    "PE (pos =0) = [sin(0/10000<sup>0</sup>), cos(0/10000<sup>0</sup>), sin(0/100), cos(0/100)] = [0, 1, 0, 1].\n",
    "\n",
    "다음 단계는 이 벡터를 임베딩 벡터 e<sub>w</sub>에 추가하고 새 벡터 e'<sub>w</sub>를 얻는 것입니다.\n",
    "\n",
    "e'<sub>w</sub> = PE (pos =0) + e<sub>w</sub>.\n",
    "\n",
    "그런 다음 pos = 1, 2, … L - 1에서 입력 시퀀스의 각 단어에 대한 e'<sub>w</sub>를 계산합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"../images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "186px",
    "left": "619px",
    "top": "238px",
    "width": "213px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
