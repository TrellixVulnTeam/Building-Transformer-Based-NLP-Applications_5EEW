{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"../images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.7 Multi-Head Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2개의 헤드가 하나보다 나을까요?  8개는 어떨까요?  셀프 어텐션에서 개선된 어텐션을 \"Multi-Head Attention\"이라고 하며, Multi-Head Attention을 사용하면 모델이 다른 위치 또는 하위 공간에 집중할 수 있습니다. \n",
    "\n",
    "Transformer 아키텍처에는 h = 8인 병렬 Attention 레이어 또는 헤드가 있습니다. 이는 모두 동시에 실행되는 8개의 Self-Attention 버전이 있음을 의미합니다.\n",
    "\n",
    "<center><figure>\n",
    "    <img src=\"../images/multiheadattention.png\" width=\"300\">\n",
    "    <figcaption>Figure 7. Multi-Head Attention</figcaption>\n",
    "</figure></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/multiheadattention1.png\" width=\"600\"> \n",
    "여기에서, $W^Q_i \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}$, $W^K_i \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}$, $W^V_i \\in \\mathbb{R}^{d_{\\text{model}} \\times d_v}$ 및 $W^O \\in \\mathbb{R}^{hd_v \\times d_{\\text{model}}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Head Attention은 기본적으로 병렬로 여러 번 반복되는 Attention입니다. 위에서 개략적으로 설명한 것과 동일한 Self-Attention 계산을 수행할 경우 h = 8이므로 횟수와 가중치가 서로 다른 8개의 <b>Z</b> 행렬로 Attention이 계산됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><figure>\n",
    "    <img src=\"../images/multihead.png\">\n",
    "    <figcaption>Figure 8. Multi-Head Attention Mechanism</figcaption>\n",
    "</figure></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보시다시피 싱글 Attention 헤드는 구조가 단순합니다. 싱글 Attention 헤드는 고유한 선형 변환을 입력 Query, Key, Value에 적용하고 각 Query와 Key 사이의 Attention 점수를 계산한 다음 이를 사용해 값에 가중치를 적용하고 합산합니다. Multi-Head Attention 블록은 여러 개의 블록을 병렬로 적용하고 출력을 연결한 후에 하나의 단일 선형 변환을 적용합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2개의 각 하위 레이어 주위에 잔차 연결이 사용되고 뒤이어 레이어 정규화가 진행됩니다. 즉, 수학 용어로 각 하위 레이어의 출력은\n",
    "LayerNorm(x + Sublayer(x))이며, 여기에서 Sublayer(x)는 하위 레이어 자체에서 구현된 함수입니다. \n",
    "\n",
    "잔차 연결 <i><b>X<sup>'</sup></b></i>를 멀티 헤드 어텐션 레이어의 출력에 추가하는 단계를 수행한 후 다음과 같이 레이어 정규화를 적용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 입력 행렬의 포지셔널 임베딩을 계산합니다.\n",
    "\n",
    "<b>X′</b> = PE(<b>X</b>) +  <b>X</b>, 여기에서 <b>X′</b> ∈ℝ<sup>n<sub>input</sub>×d<sub>model</sub></sup>.\n",
    "\n",
    "2. Multi-Head Attention 레이어를 수행하고 출력 행렬 <b>Z<sup>E</sup><sub>1,1</sub></b>을 만듭니다.\n",
    "\n",
    "MultiHead(Q, K, V ) = Concat(head<sub>1</sub>, ..., head<sub>h</sub>)W<sup>O</sup>\n",
    "\n",
    "3. 잔차 연결을 사용하고 레이어 정규화를 적용하여 <b>Z<sup>E</sup><sub>1,2</sub></b>  ∈R<sup>n<sub>input</sub>×d<sub>model</sub></sup>을 얻습니다.\n",
    "\n",
    "<b>Z<sup>E</sup><sub>1,2</sub></b> = LayerNorm(<b>X′</b> + <b>Z<sup>E</sup><sub>1,1</sub></b>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림 1의 왼쪽을 요약하면 다음과 같습니다.\n",
    "     \n",
    "Step1_out = Embedding512 + PositionEncoding512\n",
    "\n",
    "Step2_out = layer_normalization(multihead_attention(Step1_out) + Step1_out)\n",
    "\n",
    "Step3_out = layer_normalization(FFN(Step2_out) + Step2_out)\n",
    "\n",
    "out_enc = Step3_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"../images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "186px",
    "left": "619px",
    "top": "238px",
    "width": "213px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
